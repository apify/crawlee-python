# ruff: noqa: TCH003
from __future__ import annotations

from datetime import datetime
from decimal import Decimal
from enum import Enum
from typing import Annotated, Any

from pydantic import BaseModel, ConfigDict, Field
from typing_extensions import Self

from crawlee._utils.requests import compute_unique_key, unique_key_to_request_id


class BaseRequestData(BaseModel):
    """Data needed to create a new crawling request."""

    model_config = ConfigDict(populate_by_name=True)

    url: Annotated[str, Field(min_length=1)]
    """URL of the web page to crawl"""

    unique_key: Annotated[str, Field(alias='uniqueKey')]
    """A unique key identifying the request. Two requests with the same `uniqueKey` are considered as pointing to the
    same URL.

    If `uniqueKey` is not provided, then it is automatically generated by normalizing the URL.
    For example, the URL of `HTTP://www.EXAMPLE.com/something/` will produce the `uniqueKey`
    of `http://www.example.com/something`.

    Pass an arbitrary non-empty text value to the `uniqueKey` property
    to override the default behavior and specify which URLs shall be considered equal.
    """

    method: str = 'get'

    payload: str | None = None

    headers: Annotated[dict[str, str] | None, Field(default_factory=dict)] = None

    user_data: Annotated[dict[str, Any] | None, Field(alias='userData')] = None
    """Custom user data assigned to the request. Use this to save any request related data to the
    request's scope, keeping them accessible on retries, failures etc.
    """

    retry_count: Annotated[int, Field(alias='retryCount')] = 0

    no_retry: Annotated[bool, Field(alias='noRetry')] = False

    loaded_url: Annotated[str | None, Field(alias='loadedUrl')] = None

    handled_at: Annotated[datetime | None, Field(alias='handledAt')] = None

    @classmethod
    def from_url(
        cls,
        url: str,
        *,
        unique_key: str | None = None,
        **kwargs: Any,
    ) -> Self:
        """Create a new `RequestData` instance from a URL."""
        unique_key = unique_key or compute_unique_key(url)
        return cls(url=url, unique_key=unique_key, **kwargs)


class Request(BaseRequestData):
    """A crawling request (as returned from a request queue)."""

    id: str

    json_: str | None = None  # TODO: get rid of this
    # https://github.com/apify/crawlee-py/issues/94

    order_no: Decimal | None = None  # TODO: get rid of this
    # https://github.com/apify/crawlee-py/issues/94

    @classmethod
    def from_url(
        cls,
        url: str,
        *,
        unique_key: str | None = None,
        id: str | None = None,
        **kwargs: Any,
    ) -> Self:
        """Create a new `RequestData` instance from a URL."""
        unique_key = unique_key or compute_unique_key(url)
        id = id or unique_key_to_request_id(unique_key)
        return cls(url=url, unique_key=unique_key, id=id, **kwargs)

    @classmethod
    def from_base_request_data(cls, base_request_data: BaseRequestData, *, id: str | None = None) -> Self:
        """Create a complete Request object based on a BaseRequestData instance."""
        return cls(**base_request_data.model_dump(), id=id or unique_key_to_request_id(base_request_data.unique_key))

    @property
    def crawlee_data(self) -> CrawleeRequestData:
        """Crawlee-specific configuration stored in the user_data."""
        return CrawleeRequestData.model_validate(self.user_data.get('__crawlee', {}) if self.user_data else {})

    @property
    def label(self) -> str | None:
        """A string used to differentiate between arbitrary request types."""
        if self.user_data and 'label' in self.user_data:
            return str(self.user_data['label'])
        return None

    @property
    def state(self) -> RequestState | None:
        """Crawlee-specific request handling state."""
        return self.crawlee_data.state

    @state.setter
    def state(self, new_state: RequestState) -> None:
        if self.user_data is None:
            self.user_data = {}

        self.user_data.setdefault('__crawlee', {})
        self.user_data['__crawlee']['state'] = new_state

    @property
    def max_retries(self) -> int | None:
        """Crawlee-specific limit on the number of retries of the request."""
        return self.crawlee_data.max_retries

    @max_retries.setter
    def max_retries(self, new_max_retries: int) -> None:
        if self.user_data is None:
            self.user_data = {}

        self.user_data.setdefault('__crawlee', {})
        self.user_data['__crawlee']['maxRetries'] = new_max_retries


class RequestState(Enum):
    """Crawlee-specific request handling state."""

    UNPROCESSED = 0
    BEFORE_NAV = 1
    AFTER_NAV = 2
    REQUEST_HANDLER = 3
    DONE = 4
    ERROR_HANDLER = 5
    ERROR = 6
    SKIPPED = 7


class CrawleeRequestData(BaseModel):
    """Crawlee-specific configuration stored in the user_data."""

    max_retries: Annotated[int | None, Field(alias='maxRetries')] = None
    """Maximum number of retries for this request. Allows to override the global `max_request_retries` option of
    `BasicCrawler`."""

    enqueue_strategy: Annotated[str | None, Field(alias='enqueueStrategy')] = None

    state: RequestState | None = None
    """Describes the request's current lifecycle state."""

    session_rotation_count: Annotated[int | None, Field(alias='sessionRotationCount')] = None

    skip_navigation: Annotated[bool, Field(alias='skipNavigation')] = False
